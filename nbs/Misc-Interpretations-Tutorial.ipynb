{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscellaneous Interpretations\n",
    "\n",
    "This notebook covers the various interpretations that do not neatly fit into the attribution or visualisation sections. The first section trains a neural network on Imagenette which we use for the interpretations.\n",
    "\n",
    "Most methods in the misc section are structured into generating the data and plotting the data. You can thus also do your own plotting if you'd like. For example, get the top losses using `top_losses` and then plot the inputs that result in these losses using `plot_top_losses` and the output from before. This gives you more control over the data that you want to plot and prevents having to rerun the computation because the plotting isn't how you'd like it.\n",
    "\n",
    "- [Top Losses](#Top-Losses)\n",
    "- [Confusion Matrix](#Confusion-Matrix)\n",
    "- [Dataset Examples](#Dataset-Examples)\n",
    "- [Loss Landscape](#Loss-Landscape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install interpret\n",
    "!pip install git+https://github.com/ttumiel/interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torchvision import transforms, datasets\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "\n",
    "from interpret.misc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the imagenette dataset\n",
    "!wget https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-160.tgz\n",
    "!tar xf imagenette2-160.tgz\n",
    "\n",
    "imagenette_mean = [0.4616, 0.4538, 0.4254]\n",
    "imagenette_std = [0.2681, 0.2643, 0.2865]\n",
    "\n",
    "def get_transforms(size, mean, std, rotate=10, flip_lr=True, flip_ud=False):\n",
    "    \"Get some basic transforms for the dataset\"\n",
    "    val_tfms = [\n",
    "        transforms.Resize(size),\n",
    "        transforms.CenterCrop((size, size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]\n",
    "\n",
    "    tfms = [transforms.RandomRotation(rotate)] if rotate != 0 else []\n",
    "    if flip_lr: tfms += [transforms.RandomHorizontalFlip()]\n",
    "    if flip_ud: tfms += [transforms.RandomVerticalFlip()]\n",
    "\n",
    "    train_tfms = transforms.Compose(tfms+val_tfms)\n",
    "    valid_tfms = transforms.Compose(val_tfms)\n",
    "    return train_tfms, valid_tfms\n",
    "\n",
    "def imagenette(path, imsize):\n",
    "    \"Load the imagenette datasets\"\n",
    "    path = Path(path)\n",
    "    train_tfms, val_tfms = get_transforms(imsize, imagenette_mean, imagenette_std)\n",
    "    train_ds = datasets.ImageFolder(path/'train', transform=train_tfms)\n",
    "    valid_ds = datasets.ImageFolder(path/'val', transform=val_tfms)\n",
    "    return train_ds, valid_ds\n",
    "\n",
    "tds, ds = imagenette(\"imagenette2-160/\", 128)\n",
    "dl = torch.utils.data.DataLoader(tds, batch_size=128, shuffle=True)\n",
    "val_dl = torch.utils.data.DataLoader(ds, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a ResNet18 on the Imagenette Dataset\n",
    "\n",
    "Here we train a pretrained resnet18 network on the [Imagenette](https://github.com/fastai/imagenette) dataset. This is a 10 class subset of imagenet so it's very easy, so we just retrain the head of the network to output the required 10 classes. The next code block simply creates this training method.\n",
    "\n",
    "The classes are:\n",
    "\n",
    "0. Tench\n",
    "1. English springer\n",
    "1. cassette player\n",
    "1. chain saw\n",
    "1. church\n",
    "1. French horn\n",
    "1. garbage truck \n",
    "1. gas pump \n",
    "1. golf ball \n",
    "1. parachute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = torchvision.models.resnet18(pretrained=True)\n",
    "for m in network.modules():\n",
    "    if not isinstance(m, nn.BatchNorm2d):\n",
    "        m.requires_grad_(False)\n",
    "\n",
    "network.fc = nn.Linear(512, 10)\n",
    "\n",
    "def accuracy(preds, tgt): return torch.mean((preds==tgt).float()).cpu().item()\n",
    "\n",
    "def train(network, dataloader, loss_fn, epochs=3):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    network.train().to(device)\n",
    "    losses, accs = [], []\n",
    "    optim = torch.optim.Adam(network.parameters(), lr=1e-3)\n",
    "    for e in range(epochs):\n",
    "        network.train()\n",
    "        for x,y in dataloader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            y_hat = network(x)\n",
    "            loss = loss_fn(y_hat, y)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "            losses.append(loss.cpu().item())\n",
    "            accs.append(accuracy(y_hat.argmax(1), y))\n",
    "        \n",
    "        preds, tgts = validate(network, val_dl)\n",
    "        print(e, \"-  Loss:\", np.mean(losses), \"Train Acc:\", np.mean(accs), \n",
    "              \"Val Acc:\", np.mean(accuracy(preds.argmax(1), tgts)))\n",
    "        losses, accs = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(network, dl, nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Losses\n",
    "\n",
    "Plot the inputs from a particular dataset that result in the largest loss. Useful for identifying where your network is most unsure or where the inputs actually don't fit the label given (a mislabelled image).\n",
    "\n",
    "`top_losses` returns the top sorted predictions, targets, losses and all ranked indexes in a tuple. The returned values can be passed into the `plot_top_losses` function for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = top_losses(network, val_dl, nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_losses(losses, val_dl, network=network, gradcam=True, layer='layer3');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "Plot a confusion matrix for a multi-class classification or binned (rounded) regression objective. The true labels are plotted on the y-axis, with the predictions on the x-axis. This helps you find out which classes your network is favouring and where its making its mistakes across the entire dataset.\n",
    "\n",
    "Pass the output of `confusion_matrix` to `plot_confusion_matrix` to plot the matrix into an image. Use a dict for the `decode_label` parameter to translate the target labels into readable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(network, val_dl, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Examples\n",
    "\n",
    "Plot some dataset examples that maximise a particular `LayerObjective` from the visualisation objectives described in the visualisation tutorial. Useful for identifying clear examples of what the network is looking for in a particular visualisation using real examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's generate a visualisation of what the network is looking for \n",
    "# in a random layer. We can then compare this to some dataset examples.\n",
    "from interpret import OptVis\n",
    "channel = 176           # Choose a channel. Try: np.random.randint(200)\n",
    "layer = 'layer3'        # Choose a layer\n",
    "OptVis.from_layer(network, layer=layer, channel=channel).vis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_examples = dataset_examples(network, val_dl, layer, channel=channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some examples that activate the same objective\n",
    "plot_dataset_examples(ds_examples, val_dl);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Landscape\n",
    "\n",
    "Plot the loss landscape in 2 random directions around a trained network. This allows you to see how smooth the landscape around the current optimum of the network is. See https://arxiv.org/abs/1712.09913 for more details.\n",
    "\n",
    "Loss landscapes calculate the loss across a grid of points. Because of the large amount of compute, this can take long. However, we can sub-sample the dataset to around 5% and still generate the same landscape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample the validation set to reduce computation\n",
    "indices = np.random.choice(np.arange(len(ds)), int(0.1*len(ds)), replace=False)\n",
    "sampler = torch.utils.data.sampler.SubsetRandomSampler(indices)\n",
    "subset_val_dl = torch.utils.data.DataLoader(ds, batch_size=256, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = loss_landscape(network, subset_val_dl, nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_landscape(ll, angle=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_landscape(ll, mode='contour');"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Misc-Interpretations-Tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
