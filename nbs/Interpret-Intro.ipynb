{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SsBJwu2WiqTV"
   },
   "source": [
    "# Install the Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ZoczB4aiqTZ"
   },
   "outputs": [],
   "source": [
    "# Install from PyPI\n",
    "!pip install interpret-pytorch\n",
    "\n",
    "# Or install from github\n",
    "# !pip install git+https://github.com/ttumiel/interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "network = torchvision.models.googlenet(pretrained=True)\n",
    "\n",
    "# Create an OptVis object from a PyTorch model, selecting a particular layer\n",
    "optvis = OptVis.from_layer(network, layer='inception4c/branch1/conv:96')\n",
    "\n",
    "# Create visualisation\n",
    "optvis.vis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o__0xuQ4iqTe"
   },
   "source": [
    "# Generate Visualisations from a Pretrained VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fs7oOlihiqTh"
   },
   "outputs": [],
   "source": [
    "from interpret import OptVis, ImageParam, denorm\n",
    "import torchvision, torch\n",
    "\n",
    "network = torchvision.models.vgg11(pretrained=True)\n",
    "network.to('cuda' if torch.cuda.is_available() else 'cpu');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fASOhUQFiqTm"
   },
   "source": [
    "## Class Visualisations\n",
    "\n",
    "Now, we generate visualisations of the output classes. To change the class selected, simply change the value of `neuron`.\n",
    "\n",
    "We parameterise the input noise in the colour decorrelated, Fourier domain. This helps create better visualisations. For more, see: https://distill.pub/2017/feature-visualization/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "94HJ34BQiqTo"
   },
   "outputs": [],
   "source": [
    "# Select a layer from the network. Use get_layer_names() to see a list of layer names and sizes.\n",
    "layer = 'classifier/6'\n",
    "neuron = 888 # viaduct\n",
    "\n",
    "# Create an OptVis object from a PyTorch model\n",
    "optvis = OptVis.from_layer(network, layer=layer, neuron=neuron)\n",
    "\n",
    "# Parameterise input noise in colour decorrelated Fourier domain\n",
    "img_param = ImageParam(128, fft=True, decorrelate=True)\n",
    "\n",
    "# Create visualisation\n",
    "optvis.vis(img_param, thresh=(250, 500), transform=True, lr=0.05, wd=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mWvYepe2iqTt"
   },
   "source": [
    "## Channel Visualisations\n",
    "\n",
    "Now let's generate some visualisations of the channels of the convolutional layers of the network. We can see the names and number of channels of each layer by using the `get_layer_names()` method. We can then generate channel visualisations in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dpDYgD22iqTv"
   },
   "outputs": [],
   "source": [
    "from interpret import get_layer_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hbSGL6cZiqT5"
   },
   "outputs": [],
   "source": [
    "get_layer_names(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1dn0SRvviqT9"
   },
   "outputs": [],
   "source": [
    "# Select a layer from the network. Use get_layer_names() to see a list of layer names and sizes.\n",
    "layer = 'features/16'\n",
    "\n",
    "# Choose a channel that is within the size of the layer\n",
    "channel = 32\n",
    "\n",
    "# Create an OptVis object from a PyTorch model\n",
    "optvis = OptVis.from_layer(network, layer=layer, channel=channel)\n",
    "\n",
    "# Parameterise input noise in colour decorrelated Fourier domain\n",
    "img_param = ImageParam(128, fft=True, decorrelate=True)\n",
    "\n",
    "# Create visualisation\n",
    "optvis.vis(img_param, thresh=(250, 500), transform=True, lr=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QOHxdoY7iqUD"
   },
   "source": [
    "# Generate Attribution maps Using Grad-CAM\n",
    "\n",
    "Grad-CAM [1] is a technique that finds relevant features for a particular class. The method generates a heatmap over the input where the network identifies features of that particular class.\n",
    "\n",
    "[1] - https://arxiv.org/abs/1610.02391"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qOi7orZHiqUE"
   },
   "outputs": [],
   "source": [
    "from interpret import Gradcam, norm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rHnNV9zeiqUJ"
   },
   "outputs": [],
   "source": [
    "# Download an image to apply attribution to\n",
    "!curl https://www.yourpurebredpuppy.com/dogbreeds/photos2-G/german-shepherd-05.jpg -o dog.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cjC42ZjtiqUN"
   },
   "outputs": [],
   "source": [
    "img = Image.open(\"dog.jpg\")\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nhkEHMIkiqUR"
   },
   "outputs": [],
   "source": [
    "# Normalize the input image and turn it into a tensor\n",
    "data = norm(img).to('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YG8XorP2iqUV"
   },
   "outputs": [],
   "source": [
    "class_number = 235 # German Shepherd\n",
    "layer = 'features/20'\n",
    "\n",
    "# Generate the gradcam attribution map for a particular class\n",
    "attr = Gradcam(network, data, im_class=class_number, layer=layer);\n",
    "attr.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aBpjqFoViqUY"
   },
   "outputs": [],
   "source": [
    "# You can also show the heatmap without the original image to see the heatmap clearer\n",
    "attr.show(show_image=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
