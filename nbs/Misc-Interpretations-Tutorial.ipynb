{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VGAl1Cq4x_Zc"
   },
   "source": [
    "# Miscellaneous Interpretations\n",
    "\n",
    "This notebook covers the various interpretations that do not neatly fit into the attribution or visualisation sections. \n",
    "\n",
    "- [Plot Top Losses](#Plot-Top-Losses)\n",
    "- [Plot Confusion Matrix](#Plot-Confusion-Matrix)\n",
    "- [Plot Dataset Examples](#Plot-Dataset-Examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kjJQLJpwyIbk"
   },
   "outputs": [],
   "source": [
    "# Install interpret\n",
    "!pip install git+https://github.com/ttumiel/interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RrYvHvCvx_Zc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torchvision import transforms, datasets\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "\n",
    "from interpret import (plot_confusion_matrix, plot_dataset_examples, \n",
    "                       plot_top_losses, validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qzuGgiQKx_Zc"
   },
   "outputs": [],
   "source": [
    "# download the imagenette dataset\n",
    "!wget https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-160.tgz\n",
    "!tar xf imagenette2-160.tgz\n",
    "\n",
    "imagenette_mean = [0.4616, 0.4538, 0.4254]\n",
    "imagenette_std = [0.2681, 0.2643, 0.2865]\n",
    "\n",
    "def get_transforms(size, mean, std, rotate=10, flip_lr=True, flip_ud=False):\n",
    "    \"Get some basic transforms for the dataset\"\n",
    "    val_tfms = [\n",
    "        transforms.Resize(size),\n",
    "        transforms.CenterCrop((size, size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]\n",
    "\n",
    "    tfms = [transforms.RandomRotation(rotate)] if rotate != 0 else []\n",
    "    if flip_lr: tfms += [transforms.RandomHorizontalFlip()]\n",
    "    if flip_ud: tfms += [transforms.RandomVerticalFlip()]\n",
    "\n",
    "    train_tfms = transforms.Compose(tfms+val_tfms)\n",
    "    valid_tfms = transforms.Compose(val_tfms)\n",
    "    return train_tfms, valid_tfms\n",
    "\n",
    "def imagenette(path, imsize):\n",
    "    \"Load the imagenette datasets\"\n",
    "    path = Path(path)\n",
    "    train_tfms, val_tfms = get_transforms(imsize, imagenette_mean, imagenette_std)\n",
    "    train_ds = datasets.ImageFolder(path/'train', transform=train_tfms)\n",
    "    valid_ds = datasets.ImageFolder(path/'val', transform=val_tfms)\n",
    "    return train_ds, valid_ds\n",
    "\n",
    "tds, ds = imagenette(\"imagenette2-160/\", 128)\n",
    "dl = torch.utils.data.DataLoader(tds, batch_size=128, shuffle=True)\n",
    "val_dl = torch.utils.data.DataLoader(ds, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l2Yh9aIQx_Zc"
   },
   "source": [
    "## Train a ResNet18 on the Imagenette Dataset\n",
    "\n",
    "Here we train a pretrained resnet18 network on the [Imagenette](https://github.com/fastai/imagenette) dataset. This is a 10 class subset of imagenet so it's very easy, so we just retrain the head of the network to output the required 10 classes. The next code block simply creates this training method.\n",
    "\n",
    "The classes are:\n",
    "\n",
    "0. Tench\n",
    "1. English springer\n",
    "1. cassette player\n",
    "1. chain saw\n",
    "1. church\n",
    "1. French horn\n",
    "1. garbage truck \n",
    "1. gas pump \n",
    "1. golf ball \n",
    "1. parachute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t7TUXQVix_Zc"
   },
   "outputs": [],
   "source": [
    "network = torchvision.models.resnet18(pretrained=True)\n",
    "for m in network.modules():\n",
    "    if not isinstance(m, nn.BatchNorm2d):\n",
    "        m.requires_grad_(False)\n",
    "\n",
    "network.fc = nn.Linear(512, 10)\n",
    "\n",
    "def accuracy(preds, tgt): return torch.mean((preds==tgt).float()).cpu().item()\n",
    "\n",
    "def train(network, dataloader, loss_fn, epochs=3):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    network.train().to(device)\n",
    "    losses, accs = [], []\n",
    "    optim = torch.optim.Adam(network.parameters(), lr=1e-3)\n",
    "    for e in range(epochs):\n",
    "        network.train()\n",
    "        for x,y in dataloader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            y_hat = network(x)\n",
    "            loss = loss_fn(y_hat, y)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "            losses.append(loss.cpu().item())\n",
    "            accs.append(accuracy(y_hat.argmax(1), y))\n",
    "        \n",
    "        preds, tgts = validate(network, val_dl)\n",
    "        print(e, \"-  Loss:\", np.mean(losses), \"Train Acc:\", np.mean(accs), \n",
    "              \"Val Acc:\", np.mean(accuracy(preds.argmax(1), tgts)))\n",
    "        losses, accs = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FOP3TOMbx_Zc"
   },
   "outputs": [],
   "source": [
    "train(network, dl, nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EFXft6Vyx_Zc"
   },
   "source": [
    "## Plot Top Losses\n",
    "\n",
    "Plot the inputs from a particular dataset that result in the largest loss. Useful for identifying where your network is most unsure or where the inputs actually don't fit the label given (a mislabelled image).\n",
    "\n",
    "`plot_top_losses` returns the top sorted predictions, targets, losses and all ranked indexes in a tuple. The returned values can be passed back into the function (as `*top_losses_out`; see docstring) so that the computation doesn't have to be redone.\n",
    "\n",
    "`plot_top_losses` uses the `top_losses` method to generate the sorted losses. Use this if you do not want to plot the images immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s7z0i7xWx_Zc"
   },
   "outputs": [],
   "source": [
    "plot_top_losses(network, val_dl, nn.CrossEntropyLoss(), gradcam=True, layer='layer3');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NVnPjmZjx_Zc"
   },
   "source": [
    "## Plot Confusion Matrix\n",
    "\n",
    "Plot a confusion matrix for a multi-class classification or binned (rounded) regression objective. The true labels are plotted on the y-axis, with the predictions on the x-axis. This helps you find out which clases your network is favouring and where its making its mistakes across the entire dataset.\n",
    "\n",
    "`plot_confusion_matrix` uses `confusion_matrix` to generate the matrix. Use this if you do not want to plot the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YvKmt0l-x_Zc"
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(network=network, dataloader=val_dl, num_classes=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c8YFxdSnx_Zc"
   },
   "source": [
    "## Plot Dataset Examples\n",
    "\n",
    "Plot some dataset examples that maximise a particular `LayerObjective` from the visualisation objectives described in the visualisation tutorial. Useful for identifying clear examples of what the network is looking for in a particular visualisation using real examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "px9DT4XMx_Zc"
   },
   "outputs": [],
   "source": [
    "# First let's generate a visualisation of what the network is looking for \n",
    "# in a random layer\n",
    "from interpret import OptVis\n",
    "channel = 176           # Choose a channel. Try: np.random.randint(200)\n",
    "layer = 'layer3'        # Choose a layer\n",
    "OptVis.from_layer(network, layer=layer, channel=channel).vis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tAJYwx3Ix_Zc"
   },
   "outputs": [],
   "source": [
    "# Plot some examples that activate the same objective\n",
    "plot_dataset_examples(9, val_dl, network=network, layer=layer, channel=channel);"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Misc-Interpretations-Tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
