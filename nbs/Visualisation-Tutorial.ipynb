{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KO3R9JGiHFCg"
   },
   "source": [
    "# Visualisation\n",
    "\n",
    "In this notebook, we will further explore the different things that can be done with `interpret`. If you'd like a basic intro, see the [Interpret Intro Notebook](https://github.com/ttumiel/interpret/blob/master/nbs/Interpret-Intro.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cISOAygyHFCg"
   },
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3JZYXZhdHFCg"
   },
   "outputs": [],
   "source": [
    "# install from PyPI\n",
    "!pip install interpret-pytorch\n",
    "\n",
    "# Install from github\n",
    "# !pip install git+https://github.com/ttumiel/interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cgo0oC8wHFCg"
   },
   "source": [
    "## Channel Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YiexbukZHFCg"
   },
   "outputs": [],
   "source": [
    "from interpret import OptVis, ImageParam, denorm, get_layer_names\n",
    "import torchvision, torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pyyN9w9XHFCg"
   },
   "outputs": [],
   "source": [
    "# Create a network and select the particular objective that you want to optimise for.\n",
    "network = torchvision.models.googlenet(pretrained=True)\n",
    "\n",
    "# Print the layer names so that we can choose one to optimise for\n",
    "get_layer_names(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PAFQLH2tHFCg"
   },
   "source": [
    "Perhaps we want to optimise for the layer 'inception4c/branch1/conv', we can select this layer by passing it into the class method `OptVis.from_layer`. This will create an `OptVis` object with that layer as the objective. We can also choose which channel we would like to optimise for in that layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ILGEtTQGHFCg"
   },
   "outputs": [],
   "source": [
    "layer = 'inception4c/branch1/conv' # choose layer\n",
    "channel = 32 # choose channel in layer\n",
    "\n",
    "# Create an OptVis object that will create a layer objective to optimise\n",
    "optvis = OptVis.from_layer(network, layer=layer, channel=channel)\n",
    "\n",
    "# Parameterise input noise in colour decorrelated Fourier domain\n",
    "img_param = ImageParam(128, fft=True, decorrelate=True)\n",
    "\n",
    "# Create visualisation\n",
    "# thresh is a tuple containing the iterations at which to display the image\n",
    "optvis.vis(img_param, thresh=(250,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "555cEuRsHFEE"
   },
   "outputs": [],
   "source": [
    "channel = 14 # choose channel in layer\n",
    "optvis = OptVis.from_layer(network, layer=layer, channel=channel)\n",
    "optvis.vis() # you can leave out the image parameterisation to use the default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kRFQmMxqHFEE"
   },
   "source": [
    "## Manually setting objectives\n",
    "\n",
    "We can also manually create an objective and pass it to the constructor of the `OptVis` class. By creating our own objective, we can do interesting things, like combine 2 different objectives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rNXrPX5lHFEE"
   },
   "outputs": [],
   "source": [
    "from interpret.vis import LayerObjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_9j1DY_kHFEE"
   },
   "outputs": [],
   "source": [
    "objective32 = LayerObjective(network, layer, channel=32)\n",
    "objective14 = LayerObjective(network, layer, channel=14)\n",
    "objective = objective32 + objective14\n",
    "\n",
    "optvis = OptVis(network, objective)\n",
    "optvis.vis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vJ_HxxP_HFEE"
   },
   "outputs": [],
   "source": [
    "# And you can interpolate between them:\n",
    "objective = 0.75*objective32 + 0.25*objective14\n",
    "\n",
    "optvis = OptVis(network, objective)\n",
    "optvis.vis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mHY39EBZHFEE"
   },
   "source": [
    "## Other Objectives\n",
    "\n",
    "Additionally, you can optimise based on other objectives. An objective is just a class that saves a `self.loss` value to optimise. For example the `LayerObjective` hooks into the pytorch model and grabs the output of the particular layer. It then sets the negative mean of this value as the loss (i.e. we want to maximise the activation of that particular layer.)\n",
    "\n",
    "Another objective to optimise for is `DeepDream`. This creates a dream-like effect on an input image. If you'd like to see other objectives, please make a PR!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RD9mgsPTHFEE"
   },
   "outputs": [],
   "source": [
    "from interpret.vis import ImageFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iJTeJtrUHFFo"
   },
   "outputs": [],
   "source": [
    "# Download an image to apply attribution to\n",
    "!curl https://www.yourpurebredpuppy.com/dogbreeds/photos2-G/german-shepherd-05.jpg -o dog.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g_PrE65EHFFo"
   },
   "outputs": [],
   "source": [
    "# Parameterise the image\n",
    "img_param = ImageFile(\"dog.jpg\", size=256)\n",
    "img_param.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dl0FM21iHFFo"
   },
   "outputs": [],
   "source": [
    "# Deep Dream\n",
    "optvis = OptVis.from_dream(network, layer=layer)\n",
    "optvis.vis(img_param, thresh=(30,));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fam0AYwLHFFo"
   },
   "source": [
    "## Creating Objectives\n",
    "\n",
    "To create an object you can either subclass from `Objective`. This is particularly useful if you want to save some state. If you do not have any state, you can create a function that takes the network input `x` and returns some loss to minimise, and decorate it with `@Objective` so that it has all the `Objective` properties.\n",
    "\n",
    "## Improving Visualisations\n",
    "\n",
    "Visualisations don't always play nice and sometimes you may have to change a few things around. You might try some of the following:\n",
    "- Add a bit of weight decay, using the `wd` parameter in `optvis.vis`.\n",
    "- Changing the transformations. You will have to make sure the transformations operate on tensors so that the gradient can be propagated through. See `transforms.py`. This seems particularly useful for layers that are deep in the network, like the final output.\n",
    "- Add other regularisation terms like the L1 or L2 norm, or total variation to help reduce noise."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Visualisation-Tutorial.ipynb",
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
